# ReAct (Reasoning + Acting)
> ReAct란, 대규모 언어 모델(LLM)이 추론(Reasoning)과 행동(Action)을 시너지를 내어 복잡한 문제를 해결하도록 설계된 패러다임

<img width="2484" height="877" alt="image" src="https://github.com/user-attachments/assets/837debec-074a-4ba0-895c-7c86d47e27b2" />

## 개념
- 이성적으로 사고한 다음 행동한다
- 작업을 수행하기 전에 먼저 '생각'을 하고 그 다음에 '행동'하도록 지시하는 방식

## 동작 방식
- 생각-행동-관찰(reason-act-observe) 반복(loop)으로 동작
- 아래 과정을 통해 LLM은 지식 단절, 미흡한 산술 능력 또는 사적 데이터에 대한 접근성 부족과 같은 내재된 한계를 극복하기 위해 외부 함수 호출 실행
1. 생각(Reason): AI는 문제를 분석하고 다음 단계에 대한 최적의 방법 고안
  * 작업 목표를 분해하거나, 상식적 지식을 주입하거나, 진행 상황을 추적하거나, 예외를 처리하고 행동 계획을 조정하는 등 다양한 목적으로 사용되는 자유 형식의 언어 추론 흔적
2. 행동(Act): 종종 외부 도구나 API 호출. 이 행동은 외부 환경에 영향을 끼침.
3. 관찰(Observe): 행동의 결과(관찰) 분석
  * 이 피드백을 바탕으로 에이전트는 접근 방식을 미세 조정하고 다음 '생각'을 시작하며 루프 반복

## 장점
- 동적인 의사 결정 및 실시간 조정: 환경 피드백을 기반으로 행동 조절
- 향상된 인간 해석 가능성 및 신뢰성: 모델의 추론 과정이 투명하게 기록되어 인간이 이해하기 쉽고 신뢰할 수 있음
- 일반성 및 유연성: QA, 사실 검증, 텍스트 기반 게임, 웹 탐색 등 다양한 작업에 적용 가능
- 적은 수의 인컨텍스트 예시로 강력한 성능: 단 1~6개의 인컨텍스트 예시만으로도 기존 접근 방식보다 뛰어난 성능 보임
- 최신 정보 획득: 실제 웹 상호작용과 추론을 통해 최신 정보 얻음
- 휴먼-인-더-루프(Human-in-the-loop) 상호작용: 인간이 에이전트의 추론 흔적을 검사하고 편집하여 행동 수정

## 한계점
- 순차적 실행 및 비효율성: 각 단계마다 LLM 호출 필요
  * 이는 ReAct가 각 도구 사용마다 빈번하게 LLM을 호출하기 때문에 발생하는 높은 지연 시간과 비용으로 이어집니다.
- 불필요한 반복 및 조기 중단: 동일한 함수를 반복적으로 호출하거나 불완전한 중간 결과에 기반하여 조기 중단 문제
  * 이는 '무한 루프'에 빠지거나 컨텍스트 길이 제한을 초과하는 문제로 이어질 수 있습니다.
- 정확도 저하 가능성: 중간 함수 호출 결과(Observation)를 원래 프롬프트에 다시 연결하는 것이 LLM의 실행 흐름을 방해하여 정확도 낮춤
- 비효율적인 의사 결정: 때때로 단기적인 결정을 내리거나 워크플로우를 효과적으로 최적화하지 못할 수 있음
- 환각 및 오류 전파: 체인-오브-사고(Chain-of-Thought) 추론에서 환각이나 오류 전파 문제 발생
  * ReAct는 외부 지식 기반에 접근할 수 있어 더 사실적이지만, 추론 오류율이 높을 수 있으며, 유용하지 않은 검색 결과에서 회복하기 어렵습니다.
- 높은 토큰 소비: 각 단계에서 반복적으로 재계획 수행으로 인한 높은 토큰 소비
- 도구 실패에 대한 취약성: 중간 도구가 실패할 경우 시스템 취약 가능성 높음
- 
<br/>
<br/>
<br/>
출처

- REACT: SYNERGIZING REASONING AND ACTING INLANGUAGE MODELS/Department of Computer Science, Princeton University Google Research, Brain team
- AI Agents: Evolution, Architecture, and Real-World Applications/Naveen Krishnan
